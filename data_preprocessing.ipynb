{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "354358e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import RFECV, chi2\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c5d140d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        lineNo  assgNo  fixcount  firstPassCnt  P1stFixation  P2stFixation  \\\n",
       "0           1       1         1             1             1             0   \n",
       "1           2       1         1             1             1             0   \n",
       "2           3       1         1             1             1             0   \n",
       "3           4       1         1             1             1             0   \n",
       "4           5       1         1             1             1             0   \n",
       "...       ...     ...       ...           ...           ...           ...   \n",
       "10931   10932     336         1             1             1             0   \n",
       "10932   10933     336         1             1             1             0   \n",
       "10933   10934     336         1             1             1             0   \n",
       "10934   10935     336         2             1             1             0   \n",
       "10935   10936     336         1             1             1             1   \n",
       "\n",
       "       prevFixDur  firstfixDur  firstPassFixDur  nextFixDur  ...  regressLen  \\\n",
       "0               0          100              100          99  ...           0   \n",
       "1              99          278              278         159  ...           0   \n",
       "2             278          159              159         159  ...           0   \n",
       "3             159          159              159         139  ...           0   \n",
       "4             159          139              139         239  ...           0   \n",
       "...           ...          ...              ...         ...  ...         ...   \n",
       "10931         199          139              139         219  ...           0   \n",
       "10932         139          219              219          99  ...         914   \n",
       "10933         199          139              139         219  ...           0   \n",
       "10934         139          219              219          99  ...         914   \n",
       "10935          80          219              219         139  ...           0   \n",
       "\n",
       "       nextWordRegress  regressDur  pupilDiamMax  pupilDiamLag  timePrtctg  \\\n",
       "0                    0           0        0.0095         0.145      0.0131   \n",
       "1                    0           0        0.0095         0.183      0.0363   \n",
       "2                    0           0        0.0370         0.183      0.0208   \n",
       "3                    0           0        0.0370         0.183      0.0208   \n",
       "4                    0           0        0.0390         0.183      0.0182   \n",
       "...                ...         ...           ...           ...         ...   \n",
       "10931                1          99        0.4730         0.069      0.0119   \n",
       "10932                0         358        0.4730         0.069      0.0187   \n",
       "10933                1          99        0.4730         0.473      0.0084   \n",
       "10934                0         358        0.2150         0.215      0.0305   \n",
       "10935                0         457        0.0690         0.069      0.0390   \n",
       "\n",
       "       nWordsInTitle  titleNo  wordNo  label  \n",
       "0                  7        4       3      0  \n",
       "1                  7        1       1      0  \n",
       "2                  7        1       3      0  \n",
       "3                  7        1       5      0  \n",
       "4                  7        1       6      0  \n",
       "...              ...      ...     ...    ...  \n",
       "10931              7       10       6      2  \n",
       "10932              7       10       7      2  \n",
       "10933              7       10       6      2  \n",
       "10934              7       10       7      2  \n",
       "10935              7       10       1      2  \n",
       "\n",
       "[10936 rows x 28 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"eye_movements.csv\")\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e377bba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lineNo             0\n",
       "assgNo             0\n",
       "fixcount           0\n",
       "firstPassCnt       0\n",
       "P1stFixation       0\n",
       "P2stFixation       0\n",
       "prevFixDur         0\n",
       "firstfixDur        0\n",
       "firstPassFixDur    0\n",
       "nextFixDur         0\n",
       "firstSaccLen       0\n",
       "lastSaccLen        0\n",
       "prevFixPos         0\n",
       "landingPos         0\n",
       "leavingPos         0\n",
       "totalFixDur        0\n",
       "meanFixDur         0\n",
       "nRegressFrom       0\n",
       "regressLen         0\n",
       "nextWordRegress    0\n",
       "regressDur         0\n",
       "pupilDiamMax       0\n",
       "pupilDiamLag       0\n",
       "timePrtctg         0\n",
       "nWordsInTitle      0\n",
       "titleNo            0\n",
       "wordNo             0\n",
       "label              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_missing_values = df.isna().sum()\n",
    "num_missing_values # No need to remove any tuples or perform data imputation since none of the data is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412e7b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lineNo', 'assgNo', 'fixcount', 'firstPassCnt', 'P1stFixation',\n",
       "       'P2stFixation', 'prevFixDur', 'firstfixDur', 'firstPassFixDur',\n",
       "       'nextFixDur', 'firstSaccLen', 'lastSaccLen', 'prevFixPos', 'landingPos',\n",
       "       'leavingPos', 'totalFixDur', 'meanFixDur', 'nRegressFrom', 'regressLen',\n",
       "       'nextWordRegress', 'regressDur', 'pupilDiamMax', 'pupilDiamLag',\n",
       "       'timePrtctg', 'nWordsInTitle', 'titleNo', 'wordNo', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = df.columns\n",
    "attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc870e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lineNo': 10936,\n",
       " 'assgNo': 336,\n",
       " 'fixcount': 8,\n",
       " 'firstPassCnt': 7,\n",
       " 'P1stFixation': 2,\n",
       " 'P2stFixation': 2,\n",
       " 'prevFixDur': 61,\n",
       " 'firstfixDur': 63,\n",
       " 'firstPassFixDur': 111,\n",
       " 'nextFixDur': 68,\n",
       " 'firstSaccLen': 9548,\n",
       " 'lastSaccLen': 9350,\n",
       " 'prevFixPos': 7866,\n",
       " 'landingPos': 6847,\n",
       " 'leavingPos': 6900,\n",
       " 'totalFixDur': 149,\n",
       " 'meanFixDur': 254,\n",
       " 'nRegressFrom': 6,\n",
       " 'regressLen': 572,\n",
       " 'nextWordRegress': 2,\n",
       " 'regressDur': 381,\n",
       " 'pupilDiamMax': 3810,\n",
       " 'pupilDiamLag': 2517,\n",
       " 'timePrtctg': 1065,\n",
       " 'nWordsInTitle': 9,\n",
       " 'titleNo': 10,\n",
       " 'wordNo': 10,\n",
       " 'label': 3}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_unique = {}\n",
    "for attribute in attributes:\n",
    "    num_unique[attribute] = len(pd.unique(df[attribute]))\n",
    "num_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b56c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['assgNo', 'fixcount', 'firstPassCnt', 'P1stFixation', 'P2stFixation',\n",
       "       'prevFixDur', 'firstfixDur', 'firstPassFixDur', 'nextFixDur',\n",
       "       'firstSaccLen', 'lastSaccLen', 'prevFixPos', 'landingPos', 'leavingPos',\n",
       "       'totalFixDur', 'meanFixDur', 'nRegressFrom', 'regressLen',\n",
       "       'nextWordRegress', 'regressDur', 'pupilDiamMax', 'pupilDiamLag',\n",
       "       'timePrtctg', 'nWordsInTitle', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.drop(columns=['lineNo','titleNo','wordNo'], axis=1) # Contains unique values for each instance, not going to be useful\n",
    "# Also contants index values instead of actual data\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1af34994",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_full = df2.drop(columns=['label'], axis=1)\n",
    "y_full = df2['label']\n",
    "x, x_test, y, y_test = train_test_split(x_full, y_full, test_size=0.2, stratify=y_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ef3e26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P2stFixation       0.154854\n",
       "totalFixDur        0.125466\n",
       "nRegressFrom       0.212710\n",
       "nextWordRegress    0.228493\n",
       "regressDur         0.214826\n",
       "pupilDiamMax       0.122343\n",
       "timePrtctg         0.168475\n",
       "label              1.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the pearson correlation coefficients for all features to determine which features to train on\n",
    "\n",
    "corr = df2.corr()\n",
    "class_correlation = abs(corr[\"label\"])\n",
    "relevant_features = class_correlation[class_correlation > 0.1]\n",
    "relevant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7caecd56-0613-41e0-a429-3c3e893affc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              P2stFixation  totalFixDur\n",
      "P2stFixation      1.000000     0.087123\n",
      "totalFixDur       0.087123     1.000000\n",
      "\n",
      "              P2stFixation  nRegressFrom\n",
      "P2stFixation      1.000000      0.250799\n",
      "nRegressFrom      0.250799      1.000000\n",
      "\n",
      "              P2stFixation  regressDur\n",
      "P2stFixation      1.000000    0.251875\n",
      "regressDur        0.251875    1.000000\n",
      "\n",
      "                 P2stFixation  nextWordRegress\n",
      "P2stFixation         1.000000         0.131331\n",
      "nextWordRegress      0.131331         1.000000\n",
      "\n",
      "              P2stFixation  pupilDiamMax\n",
      "P2stFixation      1.000000      0.031823\n",
      "pupilDiamMax      0.031823      1.000000\n",
      "\n",
      "              P2stFixation  timePrtctg\n",
      "P2stFixation      1.000000    0.048122\n",
      "timePrtctg        0.048122    1.000000\n",
      "\n",
      "              totalFixDur  P2stFixation\n",
      "totalFixDur      1.000000      0.087123\n",
      "P2stFixation     0.087123      1.000000\n",
      "\n",
      "              totalFixDur  nRegressFrom\n",
      "totalFixDur      1.000000      0.024128\n",
      "nRegressFrom     0.024128      1.000000\n",
      "\n",
      "             totalFixDur  regressDur\n",
      "totalFixDur     1.000000    0.236419\n",
      "regressDur      0.236419    1.000000\n",
      "\n",
      "                 totalFixDur  nextWordRegress\n",
      "totalFixDur         1.000000         0.048066\n",
      "nextWordRegress     0.048066         1.000000\n",
      "\n",
      "              totalFixDur  pupilDiamMax\n",
      "totalFixDur      1.000000      0.157206\n",
      "pupilDiamMax     0.157206      1.000000\n",
      "\n",
      "             totalFixDur  timePrtctg\n",
      "totalFixDur     1.000000    0.593706\n",
      "timePrtctg      0.593706    1.000000\n",
      "\n",
      "              nRegressFrom  P2stFixation\n",
      "nRegressFrom      1.000000      0.250799\n",
      "P2stFixation      0.250799      1.000000\n",
      "\n",
      "              nRegressFrom  totalFixDur\n",
      "nRegressFrom      1.000000     0.024128\n",
      "totalFixDur       0.024128     1.000000\n",
      "\n",
      "              nRegressFrom  regressDur\n",
      "nRegressFrom      1.000000    0.330654\n",
      "regressDur        0.330654    1.000000\n",
      "\n",
      "                 nRegressFrom  nextWordRegress\n",
      "nRegressFrom         1.000000         0.122738\n",
      "nextWordRegress      0.122738         1.000000\n",
      "\n",
      "              nRegressFrom  pupilDiamMax\n",
      "nRegressFrom      1.000000      0.060834\n",
      "pupilDiamMax      0.060834      1.000000\n",
      "\n",
      "              nRegressFrom  timePrtctg\n",
      "nRegressFrom      1.000000    0.108489\n",
      "timePrtctg        0.108489    1.000000\n",
      "\n",
      "              regressDur  P2stFixation\n",
      "regressDur      1.000000      0.251875\n",
      "P2stFixation    0.251875      1.000000\n",
      "\n",
      "             regressDur  totalFixDur\n",
      "regressDur     1.000000     0.236419\n",
      "totalFixDur    0.236419     1.000000\n",
      "\n",
      "              regressDur  nRegressFrom\n",
      "regressDur      1.000000      0.330654\n",
      "nRegressFrom    0.330654      1.000000\n",
      "\n",
      "                 regressDur  nextWordRegress\n",
      "regressDur         1.000000         0.279772\n",
      "nextWordRegress    0.279772         1.000000\n",
      "\n",
      "              regressDur  pupilDiamMax\n",
      "regressDur      1.000000      0.062079\n",
      "pupilDiamMax    0.062079      1.000000\n",
      "\n",
      "            regressDur  timePrtctg\n",
      "regressDur    1.000000    0.015573\n",
      "timePrtctg    0.015573    1.000000\n",
      "\n",
      "                 nextWordRegress  P2stFixation\n",
      "nextWordRegress         1.000000      0.131331\n",
      "P2stFixation            0.131331      1.000000\n",
      "\n",
      "                 nextWordRegress  totalFixDur\n",
      "nextWordRegress         1.000000     0.048066\n",
      "totalFixDur             0.048066     1.000000\n",
      "\n",
      "                 nextWordRegress  nRegressFrom\n",
      "nextWordRegress         1.000000      0.122738\n",
      "nRegressFrom            0.122738      1.000000\n",
      "\n",
      "                 nextWordRegress  regressDur\n",
      "nextWordRegress         1.000000    0.279772\n",
      "regressDur              0.279772    1.000000\n",
      "\n",
      "                 nextWordRegress  pupilDiamMax\n",
      "nextWordRegress         1.000000      0.051035\n",
      "pupilDiamMax            0.051035      1.000000\n",
      "\n",
      "                 nextWordRegress  timePrtctg\n",
      "nextWordRegress         1.000000    0.058972\n",
      "timePrtctg              0.058972    1.000000\n",
      "\n",
      "              pupilDiamMax  P2stFixation\n",
      "pupilDiamMax      1.000000      0.031823\n",
      "P2stFixation      0.031823      1.000000\n",
      "\n",
      "              pupilDiamMax  totalFixDur\n",
      "pupilDiamMax      1.000000     0.157206\n",
      "totalFixDur       0.157206     1.000000\n",
      "\n",
      "              pupilDiamMax  nRegressFrom\n",
      "pupilDiamMax      1.000000      0.060834\n",
      "nRegressFrom      0.060834      1.000000\n",
      "\n",
      "              pupilDiamMax  regressDur\n",
      "pupilDiamMax      1.000000    0.062079\n",
      "regressDur        0.062079    1.000000\n",
      "\n",
      "                 pupilDiamMax  nextWordRegress\n",
      "pupilDiamMax         1.000000         0.051035\n",
      "nextWordRegress      0.051035         1.000000\n",
      "\n",
      "              pupilDiamMax  timePrtctg\n",
      "pupilDiamMax      1.000000    0.107287\n",
      "timePrtctg        0.107287    1.000000\n",
      "\n",
      "              timePrtctg  P2stFixation\n",
      "timePrtctg      1.000000      0.048122\n",
      "P2stFixation    0.048122      1.000000\n",
      "\n",
      "             timePrtctg  totalFixDur\n",
      "timePrtctg     1.000000     0.593706\n",
      "totalFixDur    0.593706     1.000000\n",
      "\n",
      "              timePrtctg  nRegressFrom\n",
      "timePrtctg      1.000000      0.108489\n",
      "nRegressFrom    0.108489      1.000000\n",
      "\n",
      "            timePrtctg  regressDur\n",
      "timePrtctg    1.000000    0.015573\n",
      "regressDur    0.015573    1.000000\n",
      "\n",
      "                 timePrtctg  nextWordRegress\n",
      "timePrtctg         1.000000         0.058972\n",
      "nextWordRegress    0.058972         1.000000\n",
      "\n",
      "              timePrtctg  pupilDiamMax\n",
      "timePrtctg      1.000000      0.107287\n",
      "pupilDiamMax    0.107287      1.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# features should be independent of each other, test to make sure they aren't highly correlated with each other\n",
    "feature_strings = [\"P2stFixation\", \"totalFixDur\", \"nRegressFrom\", \"regressDur\", \"nextWordRegress\", \"pupilDiamMax\", \"timePrtctg\"]  \n",
    "for i in feature_strings:\n",
    "    for j in feature_strings:\n",
    "        if i != j:\n",
    "            print(abs(df[[i,j]].corr()))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fa27c63-37c3-48ca-9300-86e5d3f9c8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P2stFixation</th>\n",
       "      <th>totalFixDur</th>\n",
       "      <th>nRegressFrom</th>\n",
       "      <th>nextWordRegress</th>\n",
       "      <th>pupilDiamMax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5060</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5367</th>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5751</th>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>0</td>\n",
       "      <td>338</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4553</th>\n",
       "      <td>0</td>\n",
       "      <td>338</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7634</th>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4346</th>\n",
       "      <td>1</td>\n",
       "      <td>238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8748 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      P2stFixation  totalFixDur  nRegressFrom  nextWordRegress  pupilDiamMax\n",
       "5060             1           99             1                0        0.2008\n",
       "5367             0          179             0                0        0.0427\n",
       "5751             0          199             0                0        0.2010\n",
       "6149             0          338             0                0        0.0326\n",
       "9996             0          119             3                1        0.3070\n",
       "...            ...          ...           ...              ...           ...\n",
       "1764             1          119             0                0        0.0369\n",
       "6017             0          199             0                0        0.0886\n",
       "4553             0          338             0                0       -0.0328\n",
       "7634             1          119             0                1        0.1766\n",
       "4346             1          238             0                0        0.1455\n",
       "\n",
       "[8748 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop all columns which have a low correlation\n",
    "# regressDur and timePtrctg have a high correlation with several other attributes and are thus not independent, drop both as well\n",
    "final_columns = [\"P2stFixation\", \"totalFixDur\", \"nRegressFrom\", \"nextWordRegress\", \"pupilDiamMax\"]  \n",
    "df_preprocessed_correlation = x\n",
    "for i in x.columns:\n",
    "    if i not in final_columns:\n",
    "        df_preprocessed_correlation = df_preprocessed_correlation.drop(columns=[i,], axis=1)\n",
    "        \n",
    "df_preprocessed_correlation\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e08d57d9-b215-4f5c-a607-2e92dc26078d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "24\n",
      "['assgNo', 'firstPassCnt', 'P1stFixation', 'P2stFixation', 'prevFixDur', 'firstfixDur', 'firstPassFixDur', 'nextFixDur', 'firstSaccLen', 'lastSaccLen', 'prevFixPos', 'landingPos', 'leavingPos', 'totalFixDur', 'meanFixDur', 'nRegressFrom', 'regressLen', 'nextWordRegress', 'regressDur', 'pupilDiamMax', 'pupilDiamLag', 'timePrtctg', 'nWordsInTitle']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assgNo</th>\n",
       "      <th>firstPassCnt</th>\n",
       "      <th>P1stFixation</th>\n",
       "      <th>P2stFixation</th>\n",
       "      <th>prevFixDur</th>\n",
       "      <th>firstfixDur</th>\n",
       "      <th>firstPassFixDur</th>\n",
       "      <th>nextFixDur</th>\n",
       "      <th>firstSaccLen</th>\n",
       "      <th>lastSaccLen</th>\n",
       "      <th>...</th>\n",
       "      <th>totalFixDur</th>\n",
       "      <th>meanFixDur</th>\n",
       "      <th>nRegressFrom</th>\n",
       "      <th>regressLen</th>\n",
       "      <th>nextWordRegress</th>\n",
       "      <th>regressDur</th>\n",
       "      <th>pupilDiamMax</th>\n",
       "      <th>pupilDiamLag</th>\n",
       "      <th>timePrtctg</th>\n",
       "      <th>nWordsInTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5060</th>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>219</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>278</td>\n",
       "      <td>141.7956</td>\n",
       "      <td>378.2317</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>0.2008</td>\n",
       "      <td>0.1788</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5367</th>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>139</td>\n",
       "      <td>375.5163</td>\n",
       "      <td>313.0994</td>\n",
       "      <td>...</td>\n",
       "      <td>179</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.1767</td>\n",
       "      <td>0.0224</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5751</th>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>278</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>318</td>\n",
       "      <td>198.5674</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>199</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.0566</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>179</td>\n",
       "      <td>338</td>\n",
       "      <td>219</td>\n",
       "      <td>172.8381</td>\n",
       "      <td>136.4441</td>\n",
       "      <td>...</td>\n",
       "      <td>338</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.2251</td>\n",
       "      <td>0.0396</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>139</td>\n",
       "      <td>139</td>\n",
       "      <td>219</td>\n",
       "      <td>1460.9867</td>\n",
       "      <td>191.0007</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>119.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7312</td>\n",
       "      <td>1</td>\n",
       "      <td>2444</td>\n",
       "      <td>0.3070</td>\n",
       "      <td>0.2405</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>219</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>80</td>\n",
       "      <td>187.2385</td>\n",
       "      <td>508.4958</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.2439</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>139</td>\n",
       "      <td>312.1158</td>\n",
       "      <td>133.0883</td>\n",
       "      <td>...</td>\n",
       "      <td>199</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>0.1576</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4553</th>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>199</td>\n",
       "      <td>338</td>\n",
       "      <td>219</td>\n",
       "      <td>521.8058</td>\n",
       "      <td>95.1223</td>\n",
       "      <td>...</td>\n",
       "      <td>338</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0328</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7634</th>\n",
       "      <td>235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>139</td>\n",
       "      <td>177.0007</td>\n",
       "      <td>551.0510</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.1766</td>\n",
       "      <td>0.1386</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4346</th>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>199</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>139</td>\n",
       "      <td>230.5266</td>\n",
       "      <td>131.1964</td>\n",
       "      <td>...</td>\n",
       "      <td>238</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>476</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.2645</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8748 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      assgNo  firstPassCnt  P1stFixation  P2stFixation  prevFixDur  \\\n",
       "5060     154             1             0             1         219   \n",
       "5367     162             1             1             0         179   \n",
       "5751     170             1             1             0         278   \n",
       "6149     181             2             1             0         219   \n",
       "9996     306             1             1             0         199   \n",
       "...      ...           ...           ...           ...         ...   \n",
       "1764      55             1             0             1         219   \n",
       "6017     178             1             1             0         219   \n",
       "4553     142             2             1             0          99   \n",
       "7634     235             1             1             1         100   \n",
       "4346     135             1             0             1         199   \n",
       "\n",
       "      firstfixDur  firstPassFixDur  nextFixDur  firstSaccLen  lastSaccLen  \\\n",
       "5060           99               99         278      141.7956     378.2317   \n",
       "5367          179              179         139      375.5163     313.0994   \n",
       "5751          199              199         318      198.5674       0.0000   \n",
       "6149          179              338         219      172.8381     136.4441   \n",
       "9996          139              139         219     1460.9867     191.0007   \n",
       "...           ...              ...         ...           ...          ...   \n",
       "1764          119              119          80      187.2385     508.4958   \n",
       "6017          199              199         139      312.1158     133.0883   \n",
       "4553          199              338         219      521.8058      95.1223   \n",
       "7634          258              258         139      177.0007     551.0510   \n",
       "4346           80               80         139      230.5266     131.1964   \n",
       "\n",
       "      ...  totalFixDur  meanFixDur  nRegressFrom  regressLen  nextWordRegress  \\\n",
       "5060  ...           99        99.0             1         278                0   \n",
       "5367  ...          179       179.0             0           0                0   \n",
       "5751  ...          199       199.0             0           0                0   \n",
       "6149  ...          338       169.0             0           0                0   \n",
       "9996  ...          119       119.0             3        7312                1   \n",
       "...   ...          ...         ...           ...         ...              ...   \n",
       "1764  ...          119       119.0             0           0                0   \n",
       "6017  ...          199       199.0             0           0                0   \n",
       "4553  ...          338       169.0             0           0                0   \n",
       "7634  ...          119       119.0             0           0                1   \n",
       "4346  ...          238       238.0             0           0                0   \n",
       "\n",
       "      regressDur  pupilDiamMax  pupilDiamLag  timePrtctg  nWordsInTitle  \n",
       "5060         139        0.2008        0.1788      0.0115              4  \n",
       "5367           0        0.0427        0.1767      0.0224              7  \n",
       "5751         199        0.2010        0.2010      0.0566              7  \n",
       "6149           0        0.0326        0.2251      0.0396              3  \n",
       "9996        2444        0.3070        0.2405      0.0080              7  \n",
       "...          ...           ...           ...         ...            ...  \n",
       "1764           0        0.0369        0.2439      0.0200              3  \n",
       "6017           0        0.0886        0.1576      0.0148              5  \n",
       "4553           0       -0.0328        0.1347      0.0243              4  \n",
       "7634        2006        0.1766        0.1386      0.0239              5  \n",
       "4346         476        0.1455        0.2645      0.0147              5  \n",
       "\n",
       "[8748 rows x 23 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform attribute selection with RFE + random forests\n",
    "# RFE (Recursive Feature Elimination) feeds the data to a model, evaluates the performance for each attribute \n",
    "# and deletes attributes which don't perform well enough\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfe = RFECV(estimator=RandomForestClassifier(n_estimators=100))\n",
    "fit = rfe.fit(x, y)\n",
    "best_features = []\n",
    "print(len(fit.support_))\n",
    "print(len(x.columns))\n",
    "for i in range(len(fit.support_)):\n",
    "    if fit.support_[i]:\n",
    "        best_features.append(x.columns[i])\n",
    "        \n",
    "print(best_features)\n",
    "df_preprocessed_rfe = x\n",
    "\n",
    "for i in x.columns:\n",
    "    if i not in best_features:\n",
    "        df_preprocessed_rfe = df_preprocessed_rfe.drop(columns=[i,], axis=1)\n",
    "        \n",
    "df_preprocessed_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 selected features\n",
      "['assgNo', 'prevFixDur', 'firstfixDur', 'firstPassFixDur', 'nextFixDur', 'firstSaccLen', 'lastSaccLen', 'prevFixPos', 'landingPos', 'leavingPos', 'totalFixDur', 'meanFixDur', 'regressLen', 'regressDur']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assgNo</th>\n",
       "      <th>prevFixDur</th>\n",
       "      <th>firstfixDur</th>\n",
       "      <th>firstPassFixDur</th>\n",
       "      <th>nextFixDur</th>\n",
       "      <th>firstSaccLen</th>\n",
       "      <th>lastSaccLen</th>\n",
       "      <th>prevFixPos</th>\n",
       "      <th>landingPos</th>\n",
       "      <th>leavingPos</th>\n",
       "      <th>totalFixDur</th>\n",
       "      <th>meanFixDur</th>\n",
       "      <th>regressLen</th>\n",
       "      <th>regressDur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5060</th>\n",
       "      <td>154</td>\n",
       "      <td>219</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>278</td>\n",
       "      <td>141.7956</td>\n",
       "      <td>378.2317</td>\n",
       "      <td>105.0762</td>\n",
       "      <td>43.1422</td>\n",
       "      <td>37.0000</td>\n",
       "      <td>99</td>\n",
       "      <td>99.0</td>\n",
       "      <td>278</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5367</th>\n",
       "      <td>162</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>139</td>\n",
       "      <td>375.5163</td>\n",
       "      <td>313.0994</td>\n",
       "      <td>312.0064</td>\n",
       "      <td>68.5164</td>\n",
       "      <td>71.0440</td>\n",
       "      <td>179</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5751</th>\n",
       "      <td>170</td>\n",
       "      <td>278</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>318</td>\n",
       "      <td>198.5674</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>159.0786</td>\n",
       "      <td>41.8390</td>\n",
       "      <td>42.7931</td>\n",
       "      <td>199</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>181</td>\n",
       "      <td>219</td>\n",
       "      <td>179</td>\n",
       "      <td>338</td>\n",
       "      <td>219</td>\n",
       "      <td>172.8381</td>\n",
       "      <td>136.4441</td>\n",
       "      <td>105.3233</td>\n",
       "      <td>64.1327</td>\n",
       "      <td>37.8847</td>\n",
       "      <td>338</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>306</td>\n",
       "      <td>199</td>\n",
       "      <td>139</td>\n",
       "      <td>139</td>\n",
       "      <td>219</td>\n",
       "      <td>1460.9867</td>\n",
       "      <td>191.0007</td>\n",
       "      <td>176.0710</td>\n",
       "      <td>1331.2506</td>\n",
       "      <td>1332.7172</td>\n",
       "      <td>119</td>\n",
       "      <td>119.0</td>\n",
       "      <td>7312</td>\n",
       "      <td>2444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>55</td>\n",
       "      <td>219</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>80</td>\n",
       "      <td>187.2385</td>\n",
       "      <td>508.4958</td>\n",
       "      <td>120.5985</td>\n",
       "      <td>70.3847</td>\n",
       "      <td>70.6629</td>\n",
       "      <td>119</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>178</td>\n",
       "      <td>219</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>139</td>\n",
       "      <td>312.1158</td>\n",
       "      <td>133.0883</td>\n",
       "      <td>319.5074</td>\n",
       "      <td>6.5192</td>\n",
       "      <td>6.5765</td>\n",
       "      <td>199</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4553</th>\n",
       "      <td>142</td>\n",
       "      <td>99</td>\n",
       "      <td>199</td>\n",
       "      <td>338</td>\n",
       "      <td>219</td>\n",
       "      <td>521.8058</td>\n",
       "      <td>95.1223</td>\n",
       "      <td>581.1730</td>\n",
       "      <td>54.7449</td>\n",
       "      <td>58.1055</td>\n",
       "      <td>338</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7634</th>\n",
       "      <td>235</td>\n",
       "      <td>100</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>139</td>\n",
       "      <td>177.0007</td>\n",
       "      <td>551.0510</td>\n",
       "      <td>268.7452</td>\n",
       "      <td>86.7078</td>\n",
       "      <td>82.7179</td>\n",
       "      <td>119</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4346</th>\n",
       "      <td>135</td>\n",
       "      <td>199</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>139</td>\n",
       "      <td>230.5266</td>\n",
       "      <td>131.1964</td>\n",
       "      <td>193.0026</td>\n",
       "      <td>44.2719</td>\n",
       "      <td>45.1276</td>\n",
       "      <td>238</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8748 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      assgNo  prevFixDur  firstfixDur  firstPassFixDur  nextFixDur  \\\n",
       "5060     154         219           99               99         278   \n",
       "5367     162         179          179              179         139   \n",
       "5751     170         278          199              199         318   \n",
       "6149     181         219          179              338         219   \n",
       "9996     306         199          139              139         219   \n",
       "...      ...         ...          ...              ...         ...   \n",
       "1764      55         219          119              119          80   \n",
       "6017     178         219          199              199         139   \n",
       "4553     142          99          199              338         219   \n",
       "7634     235         100          258              258         139   \n",
       "4346     135         199           80               80         139   \n",
       "\n",
       "      firstSaccLen  lastSaccLen  prevFixPos  landingPos  leavingPos  \\\n",
       "5060      141.7956     378.2317    105.0762     43.1422     37.0000   \n",
       "5367      375.5163     313.0994    312.0064     68.5164     71.0440   \n",
       "5751      198.5674       0.0000    159.0786     41.8390     42.7931   \n",
       "6149      172.8381     136.4441    105.3233     64.1327     37.8847   \n",
       "9996     1460.9867     191.0007    176.0710   1331.2506   1332.7172   \n",
       "...            ...          ...         ...         ...         ...   \n",
       "1764      187.2385     508.4958    120.5985     70.3847     70.6629   \n",
       "6017      312.1158     133.0883    319.5074      6.5192      6.5765   \n",
       "4553      521.8058      95.1223    581.1730     54.7449     58.1055   \n",
       "7634      177.0007     551.0510    268.7452     86.7078     82.7179   \n",
       "4346      230.5266     131.1964    193.0026     44.2719     45.1276   \n",
       "\n",
       "      totalFixDur  meanFixDur  regressLen  regressDur  \n",
       "5060           99        99.0         278         139  \n",
       "5367          179       179.0           0           0  \n",
       "5751          199       199.0           0         199  \n",
       "6149          338       169.0           0           0  \n",
       "9996          119       119.0        7312        2444  \n",
       "...           ...         ...         ...         ...  \n",
       "1764          119       119.0           0           0  \n",
       "6017          199       199.0           0           0  \n",
       "4553          338       169.0           0           0  \n",
       "7634          119       119.0           0        2006  \n",
       "4346          238       238.0           0         476  \n",
       "\n",
       "[8748 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "selector = SelectFromModel(LassoCV())\n",
    "selector.fit(x, y)\n",
    "\n",
    "\n",
    "support = selector.get_support()\n",
    "best_features = x.loc[:,support].columns.tolist()\n",
    "print(str(len(best_features)), 'selected features')\n",
    "print(best_features)\n",
    "df_preprocessed_lasso = x\n",
    "\n",
    "for i in x.columns:\n",
    "    if i not in best_features:\n",
    "        df_preprocessed_lasso = df_preprocessed_lasso.drop(columns=[i,], axis=1)\n",
    "        \n",
    "df_preprocessed_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8904/562440172.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mrfe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFECV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_features_to_select\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mbest_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    603\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_rfe_single_fit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m         scores = parallel(\n\u001b[0m\u001b[0;32m    606\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             for train, test in cv.split(X, y, groups))\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m         scores = parallel(\n\u001b[1;32m--> 606\u001b[1;33m             \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m             for train, test in cv.split(X, y, groups))\n\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\u001b[0m in \u001b[0;36m_rfe_single_fit\u001b[1;34m(rfe, estimator, X, y, train, test, scorer)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     return rfe._fit(\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         lambda estimator, features: _score(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, step_score)\u001b[0m\n\u001b[0;32m    239\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[1;31m# Get importance and rank them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m         n_stages = self._fit_stages(\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m             sample_weight_val, begin_at_stage, monitor)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m             \u001b[1;31m# fit next stage of trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[0;32m    562\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m                 random_state, X_csc, X_csr)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0m\u001b[0;32m    215\u001b[0m                      check_input=False)\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1250\u001b[0m         \"\"\"\n\u001b[0;32m   1251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1253\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    392\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# perform attribute selection with RFECV + random forests\n",
    "# RFE (Recursive Feature Elimination) feeds the data to a model, evaluates the performance for each attribute \n",
    "# and deletes attributes which don't perform well enough\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "rfe = RFECV(estimator=GradientBoostingClassifier(n_estimators=100), min_features_to_select=6, step=2)\n",
    "fit = rfe.fit(x, y)\n",
    "best_features = []\n",
    "print(len(fit.support_))\n",
    "print(len(x.columns))\n",
    "for i in range(len(fit.support_)):\n",
    "    if fit.support_[i]:\n",
    "        best_features.append(x.columns[i])\n",
    "        \n",
    "print(best_features)\n",
    "df_preprocessed_gb = x\n",
    "\n",
    "for i in x.columns:\n",
    "    if i not in best_features:\n",
    "        df_preprocessed_gb = df_preprocessed_gb.drop(columns=[i,], axis=1)\n",
    "        \n",
    "df_preprocessed_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 selected features\n",
      "['assgNo', 'firstSaccLen', 'lastSaccLen', 'prevFixPos', 'landingPos', 'leavingPos', 'pupilDiamMax', 'pupilDiamLag', 'timePrtctg', 'nWordsInTitle']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assgNo</th>\n",
       "      <th>firstSaccLen</th>\n",
       "      <th>lastSaccLen</th>\n",
       "      <th>prevFixPos</th>\n",
       "      <th>landingPos</th>\n",
       "      <th>leavingPos</th>\n",
       "      <th>pupilDiamMax</th>\n",
       "      <th>pupilDiamLag</th>\n",
       "      <th>timePrtctg</th>\n",
       "      <th>nWordsInTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5060</th>\n",
       "      <td>154</td>\n",
       "      <td>141.7956</td>\n",
       "      <td>378.2317</td>\n",
       "      <td>105.0762</td>\n",
       "      <td>43.1422</td>\n",
       "      <td>37.0000</td>\n",
       "      <td>0.2008</td>\n",
       "      <td>0.1788</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5367</th>\n",
       "      <td>162</td>\n",
       "      <td>375.5163</td>\n",
       "      <td>313.0994</td>\n",
       "      <td>312.0064</td>\n",
       "      <td>68.5164</td>\n",
       "      <td>71.0440</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.1767</td>\n",
       "      <td>0.0224</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5751</th>\n",
       "      <td>170</td>\n",
       "      <td>198.5674</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>159.0786</td>\n",
       "      <td>41.8390</td>\n",
       "      <td>42.7931</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.0566</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>181</td>\n",
       "      <td>172.8381</td>\n",
       "      <td>136.4441</td>\n",
       "      <td>105.3233</td>\n",
       "      <td>64.1327</td>\n",
       "      <td>37.8847</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.2251</td>\n",
       "      <td>0.0396</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>306</td>\n",
       "      <td>1460.9867</td>\n",
       "      <td>191.0007</td>\n",
       "      <td>176.0710</td>\n",
       "      <td>1331.2506</td>\n",
       "      <td>1332.7172</td>\n",
       "      <td>0.3070</td>\n",
       "      <td>0.2405</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>55</td>\n",
       "      <td>187.2385</td>\n",
       "      <td>508.4958</td>\n",
       "      <td>120.5985</td>\n",
       "      <td>70.3847</td>\n",
       "      <td>70.6629</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.2439</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>178</td>\n",
       "      <td>312.1158</td>\n",
       "      <td>133.0883</td>\n",
       "      <td>319.5074</td>\n",
       "      <td>6.5192</td>\n",
       "      <td>6.5765</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>0.1576</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4553</th>\n",
       "      <td>142</td>\n",
       "      <td>521.8058</td>\n",
       "      <td>95.1223</td>\n",
       "      <td>581.1730</td>\n",
       "      <td>54.7449</td>\n",
       "      <td>58.1055</td>\n",
       "      <td>-0.0328</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7634</th>\n",
       "      <td>235</td>\n",
       "      <td>177.0007</td>\n",
       "      <td>551.0510</td>\n",
       "      <td>268.7452</td>\n",
       "      <td>86.7078</td>\n",
       "      <td>82.7179</td>\n",
       "      <td>0.1766</td>\n",
       "      <td>0.1386</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4346</th>\n",
       "      <td>135</td>\n",
       "      <td>230.5266</td>\n",
       "      <td>131.1964</td>\n",
       "      <td>193.0026</td>\n",
       "      <td>44.2719</td>\n",
       "      <td>45.1276</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.2645</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8748 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      assgNo  firstSaccLen  lastSaccLen  prevFixPos  landingPos  leavingPos  \\\n",
       "5060     154      141.7956     378.2317    105.0762     43.1422     37.0000   \n",
       "5367     162      375.5163     313.0994    312.0064     68.5164     71.0440   \n",
       "5751     170      198.5674       0.0000    159.0786     41.8390     42.7931   \n",
       "6149     181      172.8381     136.4441    105.3233     64.1327     37.8847   \n",
       "9996     306     1460.9867     191.0007    176.0710   1331.2506   1332.7172   \n",
       "...      ...           ...          ...         ...         ...         ...   \n",
       "1764      55      187.2385     508.4958    120.5985     70.3847     70.6629   \n",
       "6017     178      312.1158     133.0883    319.5074      6.5192      6.5765   \n",
       "4553     142      521.8058      95.1223    581.1730     54.7449     58.1055   \n",
       "7634     235      177.0007     551.0510    268.7452     86.7078     82.7179   \n",
       "4346     135      230.5266     131.1964    193.0026     44.2719     45.1276   \n",
       "\n",
       "      pupilDiamMax  pupilDiamLag  timePrtctg  nWordsInTitle  \n",
       "5060        0.2008        0.1788      0.0115              4  \n",
       "5367        0.0427        0.1767      0.0224              7  \n",
       "5751        0.2010        0.2010      0.0566              7  \n",
       "6149        0.0326        0.2251      0.0396              3  \n",
       "9996        0.3070        0.2405      0.0080              7  \n",
       "...            ...           ...         ...            ...  \n",
       "1764        0.0369        0.2439      0.0200              3  \n",
       "6017        0.0886        0.1576      0.0148              5  \n",
       "4553       -0.0328        0.1347      0.0243              4  \n",
       "7634        0.1766        0.1386      0.0239              5  \n",
       "4346        0.1455        0.2645      0.0147              5  \n",
       "\n",
       "[8748 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbc = LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=32, colsample_bytree=0.2,\n",
    "            reg_alpha=3, reg_lambda=1, min_split_gain=0.01, min_child_weight=40)\n",
    "\n",
    "selector = SelectFromModel(lgbc)\n",
    "selector.fit(x, y)\n",
    "\n",
    "\n",
    "support = selector.get_support()\n",
    "best_features = x.loc[:,support].columns.tolist()\n",
    "print(str(len(best_features)), 'selected features')\n",
    "print(best_features)\n",
    "\n",
    "df_preprocessed_lgbm = x\n",
    "\n",
    "for i in x.columns:\n",
    "    if i not in best_features:\n",
    "        df_preprocessed_lgbm = df_preprocessed_lgbm.drop(columns=[i,], axis=1)\n",
    "        \n",
    "df_preprocessed_lgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: RandomForestClassifier; Feature Selection: control, no preprocessing [24 features] -> 0.6284277879341865\n",
      "Classifier: RandomForestClassifier; Feature Selection: Pearson correlation coefficient [5 features] -> 0.4186471663619744\n",
      "Classifier: RandomForestClassifier; Feature Selection: RFECV w/ RandomForests [23 features] -> 0.6371115173674589\n",
      "Classifier: RandomForestClassifier; Feature Selection: LassoCV  [14 features] -> 0.5361060329067642\n",
      "Classifier: RandomForestClassifier; Feature Selection: RFECV w/ GradientBoost [14 features] -> 0.6106032906764168\n",
      "Classifier: RandomForestClassifier; Feature Selection: LightGBM Selection [10 features] -> 0.5621572212065814\n",
      "\n",
      "Classifier: ExtraTreesClassifier; Feature Selection: control, no preprocessing [24 features] -> 0.656764168190128\n",
      "Classifier: ExtraTreesClassifier; Feature Selection: Pearson correlation coefficient [5 features] -> 0.409963436928702\n",
      "Classifier: ExtraTreesClassifier; Feature Selection: RFECV w/ RandomForests [23 features] -> 0.6585923217550275\n",
      "Classifier: ExtraTreesClassifier; Feature Selection: LassoCV  [14 features] -> 0.553473491773309\n",
      "Classifier: ExtraTreesClassifier; Feature Selection: RFECV w/ GradientBoost [14 features] -> 0.6270566727605119\n",
      "Classifier: ExtraTreesClassifier; Feature Selection: LightGBM Selection [10 features] -> 0.5662705667276051\n",
      "\n",
      "Classifier: BaggingClassifier; Feature Selection: control, no preprocessing [24 features] -> 0.5680987202925045\n",
      "Classifier: BaggingClassifier; Feature Selection: Pearson correlation coefficient [5 features] -> 0.4319012797074954\n",
      "Classifier: BaggingClassifier; Feature Selection: RFECV w/ RandomForests [23 features] -> 0.5749542961608776\n",
      "Classifier: BaggingClassifier; Feature Selection: LassoCV  [14 features] -> 0.5338208409506399\n",
      "Classifier: BaggingClassifier; Feature Selection: RFECV w/ GradientBoost [14 features] -> 0.5712979890310786\n",
      "Classifier: BaggingClassifier; Feature Selection: LightGBM Selection [10 features] -> 0.5475319926873857\n",
      "\n",
      "Classifier: IsolationForest; Feature Selection: control, no preprocessing [24 features] -> 0.3697440585009141\n",
      "Classifier: IsolationForest; Feature Selection: Pearson correlation coefficient [5 features] -> 0.3194698354661792\n",
      "Classifier: IsolationForest; Feature Selection: RFECV w/ RandomForests [23 features] -> 0.3720292504570384\n",
      "Classifier: IsolationForest; Feature Selection: LassoCV  [14 features] -> 0.3711151736745887\n",
      "Classifier: IsolationForest; Feature Selection: RFECV w/ GradientBoost [14 features] -> 0.3711151736745887\n",
      "Classifier: IsolationForest; Feature Selection: LightGBM Selection [10 features] -> 0.36745886654478976\n",
      "\n",
      "Classifier: AdaBoostClassifier; Feature Selection: control, no preprocessing [24 features] -> 0.5420475319926874\n",
      "Classifier: AdaBoostClassifier; Feature Selection: Pearson correlation coefficient [5 features] -> 0.4556672760511883\n",
      "Classifier: AdaBoostClassifier; Feature Selection: RFECV w/ RandomForests [23 features] -> 0.5420475319926874\n",
      "Classifier: AdaBoostClassifier; Feature Selection: LassoCV  [14 features] -> 0.48948811700182815\n",
      "Classifier: AdaBoostClassifier; Feature Selection: RFECV w/ GradientBoost [14 features] -> 0.5420475319926874\n",
      "Classifier: AdaBoostClassifier; Feature Selection: LightGBM Selection [10 features] -> 0.48857404021937845\n",
      "\n",
      "Classifier: GradientBoostingClassifier; Feature Selection: control, no preprocessing [24 features] -> 0.5804387568555759\n",
      "Classifier: GradientBoostingClassifier; Feature Selection: Pearson correlation coefficient [5 features] -> 0.4936014625228519\n",
      "Classifier: GradientBoostingClassifier; Feature Selection: RFECV w/ RandomForests [23 features] -> 0.573583180987203\n",
      "Classifier: GradientBoostingClassifier; Feature Selection: LassoCV  [14 features] -> 0.5127970749542962\n",
      "Classifier: GradientBoostingClassifier; Feature Selection: RFECV w/ GradientBoost [14 features] -> 0.5813528336380256\n",
      "Classifier: GradientBoostingClassifier; Feature Selection: LightGBM Selection [10 features] -> 0.5091407678244972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import *\n",
    "\n",
    "preprocessed_datasets = [x, df_preprocessed_correlation, df_preprocessed_rfe, df_preprocessed_lasso, df_preprocessed_gb, df_preprocessed_lgbm]\n",
    "dataset_labels = [\"control, no preprocessing\", \"Pearson correlation coefficient\", \"RFECV w/ RandomForests\", \"LassoCV \", \"RFECV w/ GradientBoost\", \"LightGBM Selection\"]\n",
    "ensemble_models = [RandomForestClassifier(), \n",
    "    ExtraTreesClassifier(), \n",
    "    BaggingClassifier(), \n",
    "    IsolationForest(), \n",
    "    AdaBoostClassifier(), \n",
    "    GradientBoostingClassifier()\n",
    "]\n",
    "\n",
    "for model in ensemble_models:\n",
    "    count = 0\n",
    "\n",
    "    for dataset in preprocessed_datasets:\n",
    "        x_test_processed = x_test\n",
    "\n",
    "        for i in x_test.columns:\n",
    "            if i not in list(dataset.columns):\n",
    "                x_test_processed = x_test_processed.drop(columns=[i,], axis=1)\n",
    "        \n",
    "        model.fit(dataset, y)\n",
    "        predicted = model.predict(x_test_processed)\n",
    "\n",
    "        print(\"Classifier: \" + type(model).__name__ + \"; Feature Selection:\", dataset_labels[count], \"[\" + str(dataset.shape[1]) + \" features] ->\", accuracy_score(y_test, predicted))\n",
    "\n",
    "        count += 1\n",
    "        \n",
    "    print()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a893f8991dc0b3f5c9efd1cf8688aead23ba8149d52e5140b8fdac1e885e777f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
